--model=dkl_llama2_7b
--use_fromage=False
--n_layers=1
--finetune_type=lora
--dataset=txgnn_did
--n_epochs=30
--batch_size=24
--learning_rate=0.0003
--scheduler_type=cosine_decay_with_warmup
--valid_every=250
--weight_decay=0.01
--wandb_track=True
