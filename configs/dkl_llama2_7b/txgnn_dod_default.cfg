--batch_size=24
--dataset=txgnn_dod
--dkl_learning_rate_multiplier=0.01
--eval_batch_size=128
--final_dim=32
--finetune_type=lora
--learning_rate=0.0003
--model=dkl_llama2_7b
--n_epochs=50
--n_layers=1
--scheduler_type=cosine_decay_with_warmup
--strategy=grid_interpolation
--use_feature_extractor=True
--use_fromage=True
--use_fromage=True
--valid_every=250
--wandb_track=True
--weight_decay=0.01
